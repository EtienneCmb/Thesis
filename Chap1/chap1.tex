\part{Étude 1: Niveau de chance et évaluation statistique des résultats de classification par apprentissage supervisé}
\label{seuil_chance}
\pagestyle{headings}

\chapter*{Introduction}
L'utilisation des outils de \textit{machine-learning}, dans le domaine des neurosciences, est de plus en plus fréquente et se sert de ces méthodes comme outils de validation. En effet, l'extraction d'attributs puis la classification de ceux-ci permet d'explorer ce qui, dans l'activité neuronale, reflète un changement d'état. Il y a donc un besoin d'évaluer la performance de décodage et sa validité statistique et donc quantifier à quel point ce décodage s'éloigne de ce que l'on pourrait atteindre par chance. \\
Lorsque l'on parle de chance dans le domaine de l'apprentissage machine, il faut distinguer la chance théorique de la chance empirique. Des problèmes à deux classes, à quatre classes ou à huit classes auront respectivement des seuils de chance de $50\%$, $25\%$ et $12.5\%$. Il faut considérer ces seuils à titre indicatif, comme première estimation, puisque en réalité ceux-ci sont atteints pour une infinité d'échantillons. Pour comprendre ce problème de seuil de chance, prenons un exemple basé sur des pièces. On sait que le seuil de chance d'avoir soit pile soit face est de $50\%$. Si on lance quatre pièces en même temps ce seuil de $50\%$ est exprimé lorsqu'il y a autant de piles que de faces, donc deux pièces chacun. Maintenant, si une pièce ne représente pas son groupe, les répartitions sont de $75\%$ contre $25\%$. Avec 10 pièces, si une pièce ne représente pas son groupe on obtient $60\%$ contre $40\%$. Pour 100 pièces on a $51\%$ contre $49\%$ etc. Plus le sac contient de pièces, plus le seuil de chance pratique va tendre vers le seuil de chance théorique. Si les spécialistes du \textit{machine-learning} ont parfaitement conscience de ce problème, la communauté neuro-scientifique affiche parfois un manque de rigueur face à cette limitation.

\vspace{1\baselineskip}
Cette étude, qui se destine principalement les étudiants ou aux personnes débutant dans le domaine, a pour objectif de quantifier ce problème du nombre d'essais et de présenter les outils pour le mesurer. Pour cela, nous avons générer des signaux Gaussien aléatoires et nous avons mesuré l'impact du nombre d'essais sur le seuil de chance ainsi que sur les principaux outils du \textit{machine-learning} (classifieur / \cv / nombre de répétitions). En effet, nous avons cherché à savoir si les classifieurs (\lda, \nb, \svm) étaient affectés de la même façon pour des petits échantillons, si certains types de \cv (\kfold et \loo) étaient plus robustes et si le nombre de répétitions permettaient de minimiser cet effet. De plus, nous rappelons que des outils analytiques (loi binomiale) ou empiriques (permutations) préviennent de ce problème du nombre d'échantillons en introduisant des valeurs statistiques. Enfin, nous avons répliqué cette étude sur des données MEG et iEEG et fournissons une toolbox Matlab pour reproduire ces résultats et contenant les outils statistiques présentés.\\

% --------------------------
%         ARTICLE
% --------------------------
\includepdf[pages={1-11}]{Chap1/Etude1_Combrisson-Jerbi-JNeuroscienceMethods_2015.pdf}

\adjustmtc